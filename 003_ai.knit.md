# Part 3 -- AI for Toxicity Prediction




In this part we experiment on using Deep Learning. We use the dataset derived from the TAME toolbox. 
Deep Learning is a modern predictive approach where neural networks are used to train a model on labelled data. The network are able to detect pattern associated to the outcome, based on the label. There are many different architectures available to choose from. Depending on the intended task, one or more of these architectures can be chosen. Also, there are a number of implementations available to build neural networks. Popular frameworks are [PyTorch](https://pytorch.org/), [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/?gclid=EAIaIQobChMIptjygcrG-wIVyOZ3Ch1omQ4MEAAYASAAEgLtF_D_BwE). PyTorch is available for Python only, whereas Keras and Tensorflow are avaible for both Python and R programming environments. Because R is relatively much used by the academic community, we use tensorflow and keras in R for this workshop. The [`{reticulate}` R package](), which is an interface to Python from R, makes it possible to setup Tensorflow in RStudio. 

It can however be quite tricky to get this technically setup, especially when you are on a new Mac with Mx-chips. Luckily there are many good resources to help you along:

 - https://developer.apple.com/metal/tensorflow-plugin/
 - https://tensorflow.rstudio.com/install/
 - https://stackoverflow.com/questions/50145643/unable-to-change-python-path-in-reticulate

For natural languge processing [Hugging Face](https://huggingface.co/) models are a good place to start.

I you are looking for a good resource to start on Deep Learning, see the excellent book from Manning that [is avaialble for R](https://www.manning.com/books/deep-learning-with-r) and for [Python](https://www.manning.com/books/deep-learning-with-python-second-edition)

Also, I can highly recommend the [Youtube channel '3Blue1Brown'](https://www.3blue1brown.com/). This channel has some of the most awesome visuals on the inner workings of deep learning I have ever seen.

## Installing Tensorflow for R
We follow the steps in theese [docs ](https://tensorflow.rstudio.com/install/) for installing Tensorflow on Windows computers. If you experience technical difficulties, we can try to help you during the workshop. We are also available after the workshop or via an online meeting to help you along if needed.



## Packages

```{.r .Rchunk}
library(tensorflow)
library(tidyverse)
library(keras)
```

## Data

```{.r .Rchunk}
substances <- read_csv(
  here::here(
    "data-raw",
    "substances.csv")) |>
  janitor::clean_names()

acute_data <- read_csv(
    here::here(
      "data-raw",
      "acute_tox_data.csv")) |>
  janitor::clean_names()
```

## Remove duplicated SMILES
Because we want to predict toxicity (class and continuous outcome of LD50_LM), we need to solve the issue of duplicated SMILES. Some smiles will have a label 'nontoxic', where that same smile will have a label 'toxic' when connected to a different compound. This can be problematic, because it will lead to ambiguous label - to - feature correlations.
To solve this, I decided to just remove all observations from the data that have a duplicated SMILES. Note that this is an easy shortcut and you should spend more time to investigate the duplication problem to decide which SMILES can be removed.

```{.r .Rchunk}
ind <- duplicated(substances$qsar_ready_smiles)
sum(ind)  
```

```{.Rout}
## [1] 477
```

```{.r .Rchunk}
substances[ind,] -> x
acute_data[ind,] -> y

y |> group_by(nontoxic) |> tally()
```

```{.Rout}
## # A tibble: 2 Ã— 2
##   nontoxic     n
##   <lgl>    <int>
## 1 FALSE      345
## 2 TRUE       132
```

```{.r .Rchunk}
## we remove the duplicates
substances <- substances[!ind, ]
acute_data <- acute_data[!ind, ]
```

## Preprocessing the data
Here we combine the data to contain the fingerprints, the `dtxsid` ids and the `nontoxic` and the `ld40_lm` column


```{.r .Rchunk}
acute_data_select <- acute_data |>
  dplyr::select(
    dtxsid,
    nontoxic,
    ld50_lm
  )

substances_select <- substances |>
  dplyr::select(
    dtxsid,
    qsar_ready_smiles
  ) 

data_nn <- full_join(acute_data_select, substances_select)
```

We reproduce part of the previous section to convert the qsar ready smiles to fingerprints


```{.r .Rchunk}
library(rcdk)
library(rcdklibs)
all_smiles <- substances_select$qsar_ready_smiles
all_mols <-parse.smiles(all_smiles)
all_mols[[1]]
```

```{.Rout}
## [1] "Java-Object{AtomContainer(1828757853, #A:7, AtomRef{Atom(1374677625, S:C, H:3, AtomType(1374677625, FC:0, Isotope(1374677625, Element(1374677625, S:C, AN:6))))}, AtomRef{Atom(1345636186, S:C, H:0, AtomType(1345636186, FC:0, Isotope(1345636186, Element(1345636186, S:C, AN:6))))}, AtomRef{Atom(963269035, S:O, H:0, AtomType(963269035, FC:0, Isotope(963269035, Element(963269035, S:O, AN:8))))}, AtomRef{Atom(1359484306, S:O, H:0, AtomType(1359484306, FC:0, Isotope(1359484306, Element(1359484306, S:O, AN:8))))}, AtomRef{Atom(2140832232, S:C, H:2, AtomType(2140832232, FC:0, Isotope(2140832232, Element(2140832232, S:C, AN:6))))}, AtomRef{Atom(157456214, S:C, H:0, AtomType(157456214, FC:0, Isotope(157456214, Element(157456214, S:C, AN:6))))}, AtomRef{Atom(1659791576, S:N, H:0, AtomType(1659791576, FC:0, Isotope(1659791576, Element(1659791576, S:N, AN:7))))}, #B:6, BondRef{Bond(1935365522, #O:SINGLE, #S:NONE, #A:2, AtomRef{Atom(1374677625, S:C, H:3, AtomType(1374677625, FC:0, Isotope(1374677625, Element(1374677625, S:C, AN:6))))}, AtomRef{Atom(1345636186, S:C, H:0, AtomType(1345636186, FC:0, Isotope(1345636186, Element(1345636186, S:C, AN:6))))}, ElectronContainer(1935365522EC:2))}, BondRef{Bond(1483022288, #O:DOUBLE, #S:NONE, #A:2, AtomRef{Atom(1345636186, S:C, H:0, AtomType(1345636186, FC:0, Isotope(1345636186, Element(1345636186, S:C, AN:6))))}, AtomRef{Atom(963269035, S:O, H:0, AtomType(963269035, FC:0, Isotope(963269035, Element(963269035, S:O, AN:8))))}, ElectronContainer(1483022288EC:4))}, BondRef{Bond(1159785389, #O:SINGLE, #S:NONE, #A:2, AtomRef{Atom(1345636186, S:C, H:0, AtomType(1345636186, FC:0, Isotope(1345636186, Element(1345636186, S:C, AN:6))))}, AtomRef{Atom(1359484306, S:O, H:0, AtomType(1359484306, FC:0, Isotope(1359484306, Element(1359484306, S:O, AN:8))))}, ElectronContainer(1159785389EC:2))}, BondRef{Bond(1410986873, #O:SINGLE, #S:NONE, #A:2, AtomRef{Atom(1359484306, S:O, H:0, AtomType(1359484306, FC:0, Isotope(1359484306, Element(1359484306, S:O, AN:8))))}, AtomRef{Atom(2140832232, S:C, H:2, AtomType(2140832232, FC:0, Isotope(2140832232, Element(2140832232, S:C, AN:6))))}, ElectronContainer(1410986873EC:2))}, BondRef{Bond(2110245805, #O:SINGLE, #S:NONE, #A:2, AtomRef{Atom(2140832232, S:C, H:2, AtomType(2140832232, FC:0, Isotope(2140832232, Element(2140832232, S:C, AN:6))))}, AtomRef{Atom(157456214, S:C, H:0, AtomType(157456214, FC:0, Isotope(157456214, Element(157456214, S:C, AN:6))))}, ElectronContainer(2110245805EC:2))}, BondRef{Bond(221036634, #O:TRIPLE, #S:NONE, #A:2, AtomRef{Atom(157456214, S:C, H:0, AtomType(157456214, FC:0, Isotope(157456214, Element(157456214, S:C, AN:6))))}, AtomRef{Atom(1659791576, S:N, H:0, AtomType(1659791576, FC:0, Isotope(1659791576, Element(1659791576, S:N, AN:7))))}, ElectronContainer(221036634EC:6))})}"
```

### Computing chemical fingerprints

We can run the same function over the entire 'all_mols' dataset, leveraging the `map()` function from the `{purrr}` R package of the `{tidyverse}`:

```{.r .Rchunk}
all.fp <- 
  map(all_mols, 
      get.fingerprint, 
      type='standard')

## Convert the pf list to a df
fp_tbl <- fingerprint::fp.to.matrix(all.fp) |> as_tibble()
## adding the predicted class (nontoxic as column)

fp_tbl <- fp_tbl |>
  mutate(
    class = ifelse(
      test = acute_data_select$nontoxic == "TRUE",  ## recode the class, 0 = nontoxic, 1 = toxic
      yes = 0,
      no = 1),
    ld50_lm = acute_data_select$ld50_lm) |>
  relocate(class, ld50_lm)
```

## Split data into training and test set

```{.r .Rchunk}
library(rsample)

## seed for reproducibility
set.seed(123)
data_split <- initial_split(fp_tbl, prop = 3/4)

## trainig data
training_data <- training(data_split) |> 
  select(-c(class, ld50_lm)) |> 
  as.matrix() |>
  array_reshape(c(nrow(training(data_split)), 1*1024))

training_labels_class <- training(data_split) |> select(class) |> 
  as.matrix() |>
#  as.integer() |>
  array_reshape(nrow(training(data_split)))

## test data
test_data <- testing(data_split) |>
  select(-c(class, ld50_lm)) |> 
  as.matrix() |>
  array_reshape(c(nrow(testing(data_split)), 1*1024))

test_labels_class <- testing(data_split) |> select(class) |> 
  as.matrix() |>
# as.integer() |>
  array_reshape(nrow(testing(data_split)))
  
training_data[1,c(1:80)]
```

```{.Rout}
##  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
## [39] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0
## [77] 0 1 0 0
```

```{.r .Rchunk}
training_labels_class[1:10]
```

```{.Rout}
##  [1] 1 1 1 1 1 1 1 1 1 0
```

```{.r .Rchunk}
test_data[1,c(1:80)]
```

```{.Rout}
##  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
## [39] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
## [77] 0 0 0 0
```

```{.r .Rchunk}
test_labels_class[1:10]
```

```{.Rout}
##  [1] 1 1 1 1 1 0 0 1 0 1
```

## Neural Network for binary classification
Here we use the fingerprints as 1D tensors, one tensor per compound

```{.r .Rchunk}
set.seed(123)
model <- keras_model_sequential(input_shape = c(1*1024)) |>
  layer_dense(units = 1024, activation = "relu") %>%
  layer_dropout(rate = 0.5) |>
  layer_dense(units = 512, activation = "relu") |>
  layer_dense(units = 512, activation = "relu") |>
  layer_dropout(0.2) %>%
  layer_dense(units = 16, activation = "relu") |>
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = "accuracy"
)

## store training in a history object so that we can see how the model is doing, also on a small validation set.
## validation split, means that 20% of the training data is reserved for validation.
history <- model %>% 
  fit(training_data, 
      training_labels_class,
      epochs = 10,
      verbose = 2,
  validation_split = 0.2
)
```

```{.Rout}
## Epoch 1/10
## 122/122 - 4s - loss: 3.2485 - accuracy: 0.6107 - val_loss: 4.0169 - val_accuracy: 0.4321 - 4s/epoch - 30ms/step
## Epoch 2/10
## 122/122 - 2s - loss: 6.9452 - accuracy: 0.6047 - val_loss: 2.3378 - val_accuracy: 0.7109 - 2s/epoch - 17ms/step
## Epoch 3/10
## 122/122 - 2s - loss: 13.0985 - accuracy: 0.6042 - val_loss: 10.0803 - val_accuracy: 0.6831 - 2s/epoch - 18ms/step
## Epoch 4/10
## 122/122 - 2s - loss: 20.7039 - accuracy: 0.6209 - val_loss: 19.6408 - val_accuracy: 0.5185 - 2s/epoch - 17ms/step
## Epoch 5/10
## 122/122 - 2s - loss: 28.3536 - accuracy: 0.6171 - val_loss: 27.3176 - val_accuracy: 0.6533 - 2s/epoch - 17ms/step
## Epoch 6/10
## 122/122 - 2s - loss: 48.6695 - accuracy: 0.5823 - val_loss: 73.9023 - val_accuracy: 0.7140 - 2s/epoch - 17ms/step
## Epoch 7/10
## 122/122 - 2s - loss: 72.1233 - accuracy: 0.6055 - val_loss: 28.6975 - val_accuracy: 0.6286 - 2s/epoch - 16ms/step
## Epoch 8/10
## 122/122 - 2s - loss: 111.9936 - accuracy: 0.5968 - val_loss: 114.1650 - val_accuracy: 0.6780 - 2s/epoch - 19ms/step
## Epoch 9/10
## 122/122 - 2s - loss: 136.5558 - accuracy: 0.5962 - val_loss: 181.5191 - val_accuracy: 0.6492 - 2s/epoch - 16ms/step
## Epoch 10/10
## 122/122 - 2s - loss: 151.6405 - accuracy: 0.5962 - val_loss: 213.9828 - val_accuracy: 0.6276 - 2s/epoch - 17ms/step
```

```{.r .Rchunk}
## we can plot the history
plot(history)
```

<img src="003_ai_files/figure-html/unnamed-chunk-9-1.png" width="672" />

```{.r .Rchunk}
## evaluate our model on thetest data
model %>% evaluate(test_data, test_labels_class, verbose = 2)
```

```{.Rout}
## 51/51 - 0s - loss: 191.5851 - accuracy: 0.6296 - 299ms/epoch - 6ms/step
```

```{.Rout}
##        loss    accuracy 
## 191.5850677   0.6296296
```

```{.r .Rchunk}
# Confusion matrix
pred <- model %>% predict(test_data, batch_size = 10)
```

```{.Rout}
## 162/162 - 0s - 436ms/epoch - 3ms/step
```

```{.r .Rchunk}
y_pred = round(pred)
confusion_matrix = table(y_pred, test_labels_class)
confusion_matrix
```

```{.Rout}
##       test_labels_class
## y_pred   0   1
##      0 251 325
##      1 275 769
```

## Optimizing the model
The model above is quite complex and big in terms of layers and number of neurons. When we look at the model on the validation set we can see in the plot that the model is overfitting. Let's start by reducing the size and complexity of the model first.

```{.r .Rchunk}
set.seed(123)
## simpler models
model <- keras_model_sequential(input_shape = c(1*1024)) |>
  layer_dense(units = 512, activation = "relu") %>%
  layer_dropout(rate = 0.9) |>
  layer_dense(units = 512, activation = "relu") %>%
  layer_dropout(rate = 0.1) |>
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = "accuracy"
)

## store training in a history object so that we can see how the model is doing, also on a small validation set.
## validation split, means that 20% of the training data is reserved for validation.
history <- model %>% 
  fit(training_data, 
      training_labels_class,
      epochs = 20,
      # Suppress logging.
      verbose = 2,
  # Calculate validation results on 20% of the training data.
  validation_split = 0.2
)
```

```{.Rout}
## Epoch 1/20
## 122/122 - 3s - loss: 0.8598 - accuracy: 0.6173 - val_loss: 0.6738 - val_accuracy: 0.6615 - 3s/epoch - 23ms/step
## Epoch 2/20
## 122/122 - 2s - loss: 0.7355 - accuracy: 0.6513 - val_loss: 0.7376 - val_accuracy: 0.6656 - 2s/epoch - 13ms/step
## Epoch 3/20
## 122/122 - 2s - loss: 0.6876 - accuracy: 0.6686 - val_loss: 0.6991 - val_accuracy: 0.6800 - 2s/epoch - 13ms/step
## Epoch 4/20
## 122/122 - 2s - loss: 0.6494 - accuracy: 0.6686 - val_loss: 0.6649 - val_accuracy: 0.6883 - 2s/epoch - 13ms/step
## Epoch 5/20
## 122/122 - 2s - loss: 0.6213 - accuracy: 0.6871 - val_loss: 0.6294 - val_accuracy: 0.6821 - 2s/epoch - 13ms/step
## Epoch 6/20
## 122/122 - 2s - loss: 0.6015 - accuracy: 0.6889 - val_loss: 0.5962 - val_accuracy: 0.7047 - 2s/epoch - 13ms/step
## Epoch 7/20
## 122/122 - 2s - loss: 0.6017 - accuracy: 0.6948 - val_loss: 0.5848 - val_accuracy: 0.7130 - 2s/epoch - 13ms/step
## Epoch 8/20
## 122/122 - 2s - loss: 0.5934 - accuracy: 0.6971 - val_loss: 0.5754 - val_accuracy: 0.7130 - 2s/epoch - 13ms/step
## Epoch 9/20
## 122/122 - 2s - loss: 0.5864 - accuracy: 0.7074 - val_loss: 0.5736 - val_accuracy: 0.7171 - 2s/epoch - 13ms/step
## Epoch 10/20
## 122/122 - 2s - loss: 0.5886 - accuracy: 0.6984 - val_loss: 0.5709 - val_accuracy: 0.7181 - 2s/epoch - 13ms/step
## Epoch 11/20
## 122/122 - 2s - loss: 0.5872 - accuracy: 0.7162 - val_loss: 0.6126 - val_accuracy: 0.7109 - 2s/epoch - 13ms/step
## Epoch 12/20
## 122/122 - 2s - loss: 0.5834 - accuracy: 0.7141 - val_loss: 0.6678 - val_accuracy: 0.6975 - 2s/epoch - 13ms/step
## Epoch 13/20
## 122/122 - 2s - loss: 0.5903 - accuracy: 0.7102 - val_loss: 0.5661 - val_accuracy: 0.7315 - 2s/epoch - 13ms/step
## Epoch 14/20
## 122/122 - 2s - loss: 0.5908 - accuracy: 0.7110 - val_loss: 0.5749 - val_accuracy: 0.7047 - 2s/epoch - 13ms/step
## Epoch 15/20
## 122/122 - 2s - loss: 0.5927 - accuracy: 0.7123 - val_loss: 0.5886 - val_accuracy: 0.7377 - 2s/epoch - 13ms/step
## Epoch 16/20
## 122/122 - 2s - loss: 0.5890 - accuracy: 0.7149 - val_loss: 0.6360 - val_accuracy: 0.7171 - 2s/epoch - 13ms/step
## Epoch 17/20
## 122/122 - 2s - loss: 0.5828 - accuracy: 0.7118 - val_loss: 0.5869 - val_accuracy: 0.7130 - 2s/epoch - 13ms/step
## Epoch 18/20
## 122/122 - 2s - loss: 0.5877 - accuracy: 0.7180 - val_loss: 0.5983 - val_accuracy: 0.7160 - 2s/epoch - 13ms/step
## Epoch 19/20
## 122/122 - 2s - loss: 0.5818 - accuracy: 0.7185 - val_loss: 0.6004 - val_accuracy: 0.7243 - 2s/epoch - 13ms/step
## Epoch 20/20
## 122/122 - 2s - loss: 0.5885 - accuracy: 0.7113 - val_loss: 0.5748 - val_accuracy: 0.7160 - 2s/epoch - 13ms/step
```

```{.r .Rchunk}
## we can plot the history
plot(history)
```

<img src="003_ai_files/figure-html/unnamed-chunk-10-1.png" width="672" />

```{.r .Rchunk}
## evaluate our model on thetest data
model %>% evaluate(test_data, test_labels_class, verbose = 2)
```

```{.Rout}
## 51/51 - 0s - loss: 0.5644 - accuracy: 0.7389 - 274ms/epoch - 5ms/step
```

```{.Rout}
##      loss  accuracy 
## 0.5644059 0.7388889
```

```{.r .Rchunk}
# Confusion matrix
pred <- model %>% predict(test_data, batch_size = 10)
```

```{.Rout}
## 162/162 - 0s - 334ms/epoch - 2ms/step
```

```{.r .Rchunk}
y_pred = round(pred)
confusion_matrix = table(y_pred, test_labels_class)
confusion_matrix
```

```{.Rout}
##       test_labels_class
## y_pred   0   1
##      0 199  96
##      1 327 998
```

## Prediction of a continuous outcome (regression)
Here we will try to predict the LD50_LM score, on the basis of the chemical fingerprints as tensors.
Because this outcome is on a continuous scale, we need a slightly different model architecture. This type of modelling approach is considered a regression problem.
We will repeat some of the preprocessing steps, because we need a different outcome variable.


```{.r .Rchunk}
## continuous outcome (training)
training_labels_ld50_lm <- training(data_split) |> 
  select(ld50_lm) |>
  as.matrix() |>
  array_reshape(nrow(training(data_split)))

## continuous outcome (testing)
test_labels_ld50_lm <- testing(data_split) |> select(ld50_lm) |> 
  as.matrix() |>
  array_reshape(nrow(testing(data_split)))
  
training_labels_ld50_lm[1:10]
```

```{.Rout}
##  [1] -0.84186795  0.08673112 -0.73614310  0.06353905  0.35389488 -0.90124980
##  [7] -0.76166688  1.45764378 -0.09421492 -0.92712769
```

```{.r .Rchunk}
test_labels_ld50_lm[1:10]
```

```{.Rout}
##  [1] -0.860995097 -0.915478522 -0.099023972 -0.580007555  0.000482997
##  [6] -0.974230381 -1.129087625  1.267963055 -1.572924787  0.022337924
```

## Regression outcome prediction
We use the same model as above but with a different output layer. Also we specify a different outcome: MAE = Mean Absolute Error, and should be as low as possible.

```{.r .Rchunk}
set.seed(123)
model <- keras_model_sequential(input_shape = c(1*1024)) |>
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.2) |>
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.1) |>
#  layer_dense(units = 16, activation = "relu") %>%
  layer_dense(units = 1)

model %>% compile(
  optimizer = "rmsprop",
  loss = "mse",
  metrics = c("mae")
)

history <- model %>% 
  fit(training_data, 
      training_labels_ld50_lm,
      epochs = 20,
      # Suppress logging.
      verbose = 2,
  # Calculate validation results on 20% of the training data.
  validation_split = 0.2
)
```

```{.Rout}
## Epoch 1/20
## 122/122 - 3s - loss: 0.7465 - mae: 0.6614 - val_loss: 0.5158 - val_mae: 0.5425 - 3s/epoch - 21ms/step
## Epoch 2/20
## 122/122 - 1s - loss: 0.5995 - mae: 0.5890 - val_loss: 0.5569 - val_mae: 0.5622 - 1s/epoch - 11ms/step
## Epoch 3/20
## 122/122 - 1s - loss: 0.5926 - mae: 0.5853 - val_loss: 0.7045 - val_mae: 0.6329 - 1s/epoch - 11ms/step
## Epoch 4/20
## 122/122 - 1s - loss: 0.6165 - mae: 0.5947 - val_loss: 0.8744 - val_mae: 0.7089 - 1s/epoch - 11ms/step
## Epoch 5/20
## 122/122 - 1s - loss: 0.6426 - mae: 0.6110 - val_loss: 0.5514 - val_mae: 0.5633 - 1s/epoch - 11ms/step
## Epoch 6/20
## 122/122 - 1s - loss: 0.7446 - mae: 0.6561 - val_loss: 0.6669 - val_mae: 0.6087 - 1s/epoch - 11ms/step
## Epoch 7/20
## 122/122 - 1s - loss: 0.7956 - mae: 0.6735 - val_loss: 0.5632 - val_mae: 0.5937 - 1s/epoch - 11ms/step
## Epoch 8/20
## 122/122 - 1s - loss: 0.9153 - mae: 0.7174 - val_loss: 0.6439 - val_mae: 0.6483 - 1s/epoch - 11ms/step
## Epoch 9/20
## 122/122 - 1s - loss: 0.9916 - mae: 0.7570 - val_loss: 0.5924 - val_mae: 0.6022 - 1s/epoch - 11ms/step
## Epoch 10/20
## 122/122 - 1s - loss: 1.1065 - mae: 0.7839 - val_loss: 0.6522 - val_mae: 0.6248 - 1s/epoch - 12ms/step
## Epoch 11/20
## 122/122 - 1s - loss: 1.1980 - mae: 0.8210 - val_loss: 0.9385 - val_mae: 0.7488 - 1s/epoch - 11ms/step
## Epoch 12/20
## 122/122 - 1s - loss: 1.4481 - mae: 0.8594 - val_loss: 4.8296 - val_mae: 1.6073 - 1s/epoch - 11ms/step
## Epoch 13/20
## 122/122 - 1s - loss: 1.4374 - mae: 0.8765 - val_loss: 1.4229 - val_mae: 0.9055 - 1s/epoch - 11ms/step
## Epoch 14/20
## 122/122 - 1s - loss: 1.6287 - mae: 0.9231 - val_loss: 0.9224 - val_mae: 0.7181 - 1s/epoch - 11ms/step
## Epoch 15/20
## 122/122 - 1s - loss: 1.7654 - mae: 0.9569 - val_loss: 0.8705 - val_mae: 0.7139 - 1s/epoch - 11ms/step
## Epoch 16/20
## 122/122 - 1s - loss: 1.7528 - mae: 0.9625 - val_loss: 0.7229 - val_mae: 0.6497 - 1s/epoch - 11ms/step
## Epoch 17/20
## 122/122 - 2s - loss: 2.0076 - mae: 0.9982 - val_loss: 1.0959 - val_mae: 0.7843 - 2s/epoch - 12ms/step
## Epoch 18/20
## 122/122 - 1s - loss: 2.2766 - mae: 1.0309 - val_loss: 1.7920 - val_mae: 1.0086 - 1s/epoch - 11ms/step
## Epoch 19/20
## 122/122 - 1s - loss: 2.3609 - mae: 1.0739 - val_loss: 7.5743 - val_mae: 2.1314 - 1s/epoch - 11ms/step
## Epoch 20/20
## 122/122 - 1s - loss: 2.4172 - mae: 1.1198 - val_loss: 0.9689 - val_mae: 0.7420 - 1s/epoch - 11ms/step
```

```{.r .Rchunk}
plot(history)
```

<img src="003_ai_files/figure-html/unnamed-chunk-12-1.png" width="672" />

```{.r .Rchunk}
model %>% evaluate(test_data,  test_labels_ld50_lm, verbose = 2)
```

```{.Rout}
## 51/51 - 0s - loss: 1.0029 - mae: 0.7396 - 198ms/epoch - 4ms/step
```

```{.Rout}
##      loss       mae 
## 1.0028965 0.7395556
```

```{.r .Rchunk}
model |> predict(test_data) -> predictions
```

```{.Rout}
## 51/51 - 0s - 147ms/epoch - 3ms/step
```

```{.r .Rchunk}
predictions[1,]
```

```{.Rout}
## [1] -0.2360807
```

```{.r .Rchunk}
realvalue <- test_labels_ld50_lm[1]
realvalue
```

```{.Rout}
## [1] -0.8609951
```

```{.r .Rchunk}
## lets plot the correlations
predictions <- tibble(
  .pred = predictions,
  .real = test_labels_ld50_lm
)

origin <- tibble(
  x = seq(-3, 5, length.out = 9),
  y = seq(-3, 5, length.out = 9)
)

predictions |>
  ggplot(aes(x = .real, y = .pred)) +
  geom_point(shape = 1) +
  geom_line(data = origin, aes(x = x, y = y), colour = "darkred")
```

<img src="003_ai_files/figure-html/unnamed-chunk-12-2.png" width="672" />

## Maybe we can do better when we use different embeddings
Transformer foundation models have revolutionized Deep Learning over the past three years. They were first created and used to solve complex Natural Language Processing tasks. Now they are also used to create better representations for compounds, DNA and even for meta-genomics. Here we used the [ChemBERT model available from Hugging Face](https://huggingface.co/jiangg/chembert_cased) to create alternative structural embedding for our compounds, based on the 'QSAR ready SMILES'.
The dataset containing the embeddings is here: `./machine-learning-with-r/data-raw/chembert_embeddings.tar.gz`. The archive a a gunzipped/tar archive and needs to be extracted first. We can do that using R.

The data file with ChemBERTa embeddings was created using a python script which can be found in `./ChemBERT/chembert.py`. This folder also includes a `requirements.txt` file that can be used to create a reproducible Python environment. See e.g. [this resource](https://www.folkstalk.com/2022/09/conda-create-environment-based-on-requirements-txt-with-code-examples.html) on how to do that.


```{.r .Rchunk}
# Define the path to your .tar.gz file
file_path <- here::here(
  "data-raw",
  "chembert_embeddings.tar.gz"
)

# Define the directory where you want to extract the files
extraction_directory <- here::here(
  "data"
)

# Use the untar function to extract the files
untar(tarfile = file_path, exdir = extraction_directory)
```

## Read Chembert embeddings 

```{.r .Rchunk}
file <- here::here(
  "data", 
  "aspis_workshop_chembert_embeddings.csv"
  )

chembert <- read_csv(
  file
) |> janitor::clean_names()

## remove duplicated smiels rows
chembert <- chembert[!ind, ]
## let's add the class and the ld50_lm to this data
chembert <- chembert |>
  mutate(
    class = fp_tbl$class,
    ld50_lm = fp_tbl$ld50_lm
  ) |>
  relocate(class, ld50_lm)
```

## Preprocessing for Neural Network
Now that we have the data with new embeddings, let's preprocess this data. We have seen how to do this before.

```{.r .Rchunk}
library(rsample)

## seed for reproducibility
set.seed(123)
data_split <- initial_split(chembert, prop = 3/4)

## trainig data
training_data <- training(data_split) |> 
  select(-c(dtxsid, class, ld50_lm)) |> 
  as.matrix() |>
  array_reshape(c(nrow(training(data_split)), 1*768))

training_labels_class <- training(data_split) |> select(class) |> 
  as.matrix() |>
#  as.integer() |>
  array_reshape(c(nrow(training(data_split))))

## test data
test_data <- testing(data_split) |>
  select(-c(dtxsid, class, ld50_lm)) |> 
  as.matrix() |>
  array_reshape(c(nrow(testing(data_split)), 1*768))

test_labels_class <- testing(data_split) |> select(class) |> 
  as.matrix() |>
# as.integer() |>
  array_reshape(c(nrow(testing(data_split))))
  
training_data[1,c(1:80)]
```

```{.Rout}
##  [1]  0.0254050419  0.0154049937 -0.0655134022  0.0306613408 -0.0601363815
##  [6]  0.0489101000 -0.0246895719  0.0141630871 -0.0178151038 -0.0081695328
## [11] -0.0275452882  0.0234250128  0.0704228505 -0.0029000093  0.0630686954
## [16] -0.0156053510 -0.0222535580  0.0078548789 -0.0355978198  0.0071175853
## [21] -0.0487961806  0.0410307944 -0.0322892331  0.0742122233 -0.0447730497
## [26]  0.0235035215 -0.0464631654  0.0186881144  0.0311555974 -0.0489444248
## [31]  0.0025621634  0.0194153879  0.0057644229  0.0063343449  0.0540660098
## [36] -0.0367920771  0.0105397813 -0.0023371670 -0.0183491036 -0.0258622784
## [41] -0.0248740204  0.0699157640  0.0297054294  0.0023921062 -0.0155654177
## [46]  0.0038752174  0.0069432743 -0.0348150916 -0.0424550697  0.0012825029
## [51] -0.0536092520 -0.0425254479  0.0370006636  0.0447047576 -0.0676804781
## [56] -0.0003236251 -0.0070984513  0.0421536304  0.0382864550 -0.0368142016
## [61] -0.0356510803  0.0268683508  0.0562435985  0.0523131751  0.0123353591
## [66]  0.0047172057  0.0176787991  0.0310021136  0.0285272095 -0.0201660376
## [71] -0.0447321758 -0.0332175717  0.0065256543 -0.0251945611 -0.0276289731
## [76] -0.0670878589  0.0449889377  0.0026088408  0.0427789725 -0.0111714564
```

```{.r .Rchunk}
training_labels_class[1:10]
```

```{.Rout}
##  [1] 1 1 1 1 1 1 1 1 1 0
```

```{.r .Rchunk}
test_data[1,c(1:80)]
```

```{.Rout}
##  [1] -0.041954610  0.007999669 -0.060547303  0.020834871 -0.055912253
##  [6]  0.022221927 -0.033818707  0.006300043 -0.026146408 -0.031368002
## [11] -0.061078932 -0.008795224  0.063303508  0.017697614  0.069213994
## [16] -0.002286052 -0.035509251 -0.006648304  0.048325881 -0.035570502
## [21] -0.026546216  0.040318921 -0.061960440  0.074652292 -0.041194953
## [26]  0.045077711 -0.039544150  0.045900088  0.046960242 -0.047569938
## [31]  0.012769441  0.025035195  0.036790010 -0.001672810  0.054527562
## [36] -0.042152740  0.006137548  0.001289501  0.016170997 -0.003948050
## [41]  0.017639181  0.074205570  0.024836546 -0.025110565  0.007694331
## [46]  0.018632298 -0.041178722 -0.063967653 -0.055773046 -0.010447158
## [51] -0.058174152 -0.063343994  0.012633751  0.053550139 -0.028193189
## [56] -0.018905245  0.001865275  0.060366828  0.022999631  0.017402306
## [61] -0.031685811  0.047336023  0.029912606  0.013602667  0.043920144
## [66]  0.029148184 -0.014992764  0.014078178 -0.026637942 -0.010121663
## [71] -0.037662666 -0.025306346  0.012428138 -0.030554749  0.022722462
## [76] -0.036704749  0.044011604  0.042527672  0.050988272 -0.044336054
```

```{.r .Rchunk}
test_labels_class[1:10]
```

```{.Rout}
##  [1] 1 1 1 1 1 0 0 1 0 1
```

## Neural Network for binary classification
Here we use the chembert embeddings as 1D tensors, one tensor per compound

```{.r .Rchunk}
set.seed(123)
## simpler models
model <- keras_model_sequential(input_shape = c(1*768)) |>
  layer_dense(units = 512, activation = "relu") %>%
  layer_dropout(rate = 0.5) |>
 # layer_dense(units = 512, activation = "relu") %>
  layer_dense(units = 512, activation = "relu") %>%
  layer_dropout(rate = 0.9) |>
#  layer_dense(units = 258, activation = "relu") %>%
#  layer_dropout(rate = 0.9) |>
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = "accuracy"
)

## store training in a history object so that we can see how the model is doing, also on a small validation set.
## validation split, means that 20% of the training data is reserved for validation.
history <- model %>% 
  fit(training_data, 
      training_labels_class,
      epochs = 20,
      # Suppress logging.
      verbose = 2,
  # Calculate validation results on 20% of the training data.
  validation_split = 0.2
)
```

```{.Rout}
## Epoch 1/20
## 122/122 - 3s - loss: 0.6792 - accuracy: 0.6266 - val_loss: 0.6337 - val_accuracy: 0.6461 - 3s/epoch - 23ms/step
## Epoch 2/20
## 122/122 - 2s - loss: 0.6673 - accuracy: 0.6390 - val_loss: 0.6332 - val_accuracy: 0.6461 - 2s/epoch - 13ms/step
## Epoch 3/20
## 122/122 - 2s - loss: 0.6568 - accuracy: 0.6459 - val_loss: 0.6373 - val_accuracy: 0.6461 - 2s/epoch - 13ms/step
## Epoch 4/20
## 122/122 - 2s - loss: 0.6582 - accuracy: 0.6372 - val_loss: 0.6315 - val_accuracy: 0.6451 - 2s/epoch - 14ms/step
## Epoch 5/20
## 122/122 - 2s - loss: 0.6453 - accuracy: 0.6498 - val_loss: 0.6308 - val_accuracy: 0.6481 - 2s/epoch - 13ms/step
## Epoch 6/20
## 122/122 - 2s - loss: 0.6454 - accuracy: 0.6472 - val_loss: 0.6276 - val_accuracy: 0.6471 - 2s/epoch - 13ms/step
## Epoch 7/20
## 122/122 - 2s - loss: 0.6455 - accuracy: 0.6436 - val_loss: 0.6880 - val_accuracy: 0.6461 - 2s/epoch - 13ms/step
## Epoch 8/20
## 122/122 - 2s - loss: 0.6443 - accuracy: 0.6503 - val_loss: 0.6684 - val_accuracy: 0.6471 - 2s/epoch - 13ms/step
## Epoch 9/20
## 122/122 - 2s - loss: 0.6406 - accuracy: 0.6552 - val_loss: 0.6518 - val_accuracy: 0.6451 - 2s/epoch - 13ms/step
## Epoch 10/20
## 122/122 - 2s - loss: 0.6436 - accuracy: 0.6526 - val_loss: 0.6754 - val_accuracy: 0.6471 - 2s/epoch - 13ms/step
## Epoch 11/20
## 122/122 - 2s - loss: 0.6363 - accuracy: 0.6629 - val_loss: 0.6532 - val_accuracy: 0.6461 - 2s/epoch - 13ms/step
## Epoch 12/20
## 122/122 - 2s - loss: 0.6415 - accuracy: 0.6518 - val_loss: 0.6431 - val_accuracy: 0.6471 - 2s/epoch - 13ms/step
## Epoch 13/20
## 122/122 - 2s - loss: 0.6410 - accuracy: 0.6547 - val_loss: 0.6769 - val_accuracy: 0.6471 - 2s/epoch - 13ms/step
## Epoch 14/20
## 122/122 - 2s - loss: 0.6353 - accuracy: 0.6629 - val_loss: 0.6710 - val_accuracy: 0.6461 - 2s/epoch - 13ms/step
## Epoch 15/20
## 122/122 - 2s - loss: 0.6374 - accuracy: 0.6472 - val_loss: 0.6706 - val_accuracy: 0.6471 - 2s/epoch - 13ms/step
## Epoch 16/20
## 122/122 - 2s - loss: 0.6377 - accuracy: 0.6608 - val_loss: 0.6964 - val_accuracy: 0.6451 - 2s/epoch - 13ms/step
## Epoch 17/20
## 122/122 - 2s - loss: 0.6380 - accuracy: 0.6585 - val_loss: 0.7255 - val_accuracy: 0.6481 - 2s/epoch - 12ms/step
## Epoch 18/20
## 122/122 - 2s - loss: 0.6326 - accuracy: 0.6588 - val_loss: 0.7243 - val_accuracy: 0.6481 - 2s/epoch - 13ms/step
## Epoch 19/20
## 122/122 - 2s - loss: 0.6314 - accuracy: 0.6714 - val_loss: 0.7204 - val_accuracy: 0.6451 - 2s/epoch - 13ms/step
## Epoch 20/20
## 122/122 - 2s - loss: 0.6353 - accuracy: 0.6593 - val_loss: 0.7623 - val_accuracy: 0.6471 - 2s/epoch - 13ms/step
```

```{.r .Rchunk}
## we can plot the history
plot(history)
```

<img src="003_ai_files/figure-html/unnamed-chunk-16-1.png" width="672" />

```{.r .Rchunk}
## evaluate our model on thetest data
model %>% evaluate(test_data, test_labels_class, verbose = 2)
```

```{.Rout}
## 51/51 - 0s - loss: 0.7161 - accuracy: 0.6747 - 289ms/epoch - 6ms/step
```

```{.Rout}
##      loss  accuracy 
## 0.7160648 0.6746914
```

```{.r .Rchunk}
# Confusion matrix
pred <- model %>% predict(test_data, batch_size = 10)
```

```{.Rout}
## 162/162 - 0s - 347ms/epoch - 2ms/step
```

```{.r .Rchunk}
y_pred = round(pred)
confusion_matrix = table(y_pred, test_labels_class)
confusion_matrix
```

```{.Rout}
##       test_labels_class
## y_pred    0    1
##      0    0    1
##      1  526 1093
```

So it seems that using the ChemBERT embeddings did not improve our model for the toxicity classification (binary) task. Let's see how ChemBERT is doing on the regression task.

## Prediction the LD50_LM with the ChemBERT embeddings

```{.r .Rchunk}
set.seed(123)
## simpler models
model <- keras_model_sequential(input_shape = c(1*768)) |>
  layer_dense(units = 512, activation = "relu") %>%
#  layer_dropout(rate = 0.1) |>
  layer_dense(units = 512, activation = "relu") %>%
  layer_dropout(rate = 0.9) |>
 # layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1)

model %>% compile(
  optimizer = "rmsprop",
  loss = "mse",
  metrics = c("mae")
)

history <- model %>% 
  fit(training_data, 
      training_labels_ld50_lm,
      epochs = 10,
      # Suppress logging.
      verbose = 2,
  # Calculate validation results on 20% of the training data.
  validation_split = 0.2
)
```

```{.Rout}
## Epoch 1/10
## 122/122 - 2s - loss: 0.8233 - mae: 0.6971 - val_loss: 0.6968 - val_mae: 0.6185 - 2s/epoch - 20ms/step
## Epoch 2/10
## 122/122 - 1s - loss: 0.7508 - mae: 0.6726 - val_loss: 0.6706 - val_mae: 0.6110 - 1s/epoch - 11ms/step
## Epoch 3/10
## 122/122 - 1s - loss: 0.7217 - mae: 0.6549 - val_loss: 0.6360 - val_mae: 0.6071 - 1s/epoch - 11ms/step
## Epoch 4/10
## 122/122 - 1s - loss: 0.7269 - mae: 0.6576 - val_loss: 1.0106 - val_mae: 0.7477 - 1s/epoch - 11ms/step
## Epoch 5/10
## 122/122 - 1s - loss: 0.7157 - mae: 0.6529 - val_loss: 0.6222 - val_mae: 0.6043 - 1s/epoch - 11ms/step
## Epoch 6/10
## 122/122 - 1s - loss: 0.7019 - mae: 0.6465 - val_loss: 0.6319 - val_mae: 0.6048 - 1s/epoch - 11ms/step
## Epoch 7/10
## 122/122 - 1s - loss: 0.7068 - mae: 0.6507 - val_loss: 0.7416 - val_mae: 0.6325 - 1s/epoch - 11ms/step
## Epoch 8/10
## 122/122 - 1s - loss: 0.6986 - mae: 0.6491 - val_loss: 1.3255 - val_mae: 0.8991 - 1s/epoch - 11ms/step
## Epoch 9/10
## 122/122 - 1s - loss: 0.7014 - mae: 0.6427 - val_loss: 0.9554 - val_mae: 0.7205 - 1s/epoch - 11ms/step
## Epoch 10/10
## 122/122 - 1s - loss: 0.7057 - mae: 0.6468 - val_loss: 0.7693 - val_mae: 0.6485 - 1s/epoch - 11ms/step
```

```{.r .Rchunk}
plot(history)
```

<img src="003_ai_files/figure-html/unnamed-chunk-17-1.png" width="672" />

```{.r .Rchunk}
model %>% evaluate(test_data,  test_labels_ld50_lm, verbose = 2)
```

```{.Rout}
## 51/51 - 0s - loss: 0.8498 - mae: 0.6751 - 197ms/epoch - 4ms/step
```

```{.Rout}
##      loss       mae 
## 0.8498487 0.6750959
```

```{.r .Rchunk}
model |> predict(test_data) -> predictions
```

```{.Rout}
## 51/51 - 0s - 146ms/epoch - 3ms/step
```

```{.r .Rchunk}
predictions[1,]
```

```{.Rout}
## [1] -0.8110058
```

```{.r .Rchunk}
realvalue <- test_labels_ld50_lm[1]
realvalue
```

```{.Rout}
## [1] -0.8609951
```

```{.r .Rchunk}
## lets plot the correlations
predictions <- tibble(
  .pred = predictions,
  .real = test_labels_ld50_lm
)

origin <- tibble(
  x = seq(-3, 5, length.out = 9),
  y = seq(-3, 5, length.out = 9)
)

predictions |>
  ggplot(aes(x = .real, y = .pred)) +
  geom_point(shape = 1) +
  geom_line(data = origin, aes(x = x, y = y), colour = "darkred")
```

<img src="003_ai_files/figure-html/unnamed-chunk-17-2.png" width="672" />

## Classic machine learning approach with reggression trees 
It seems the ChemBERT embeddings did not improve our predictions (for now). How can we then make use of this new way of encoding. 
First, we can use the ChemBERT embedding to create a more robust simulirity matrix, that can benefit read accross. We preformed 
We will demonstrate this with an example where we combine structural embeddings created with ChemBERT and a Natural Language Based biological enrichment, to perform read across. This concept is also presented on a poster during the ESTIV conference (poster: Abstract #492)

Another possibility is to use these new embeddings to do a different, more classical modelling approach. Maybe bringing out the big gun of Deep Learning is not always the best option. Here we will explore if an XGBoost model, which is a variant of the regression tree models (such as Random Forest), can bring a better model to the table. 

We will build the model, using the `{tidymodels}` approach. This approach consists of the following steps

 - Split the data
 - Define a models recipe
 - Define a recipe for data pre-processing
 - Combine the recipes in a workflow
 - Fit the model
 - Evaluate the model
 - Tune the model using a grid to find the optimal hyperparameters
 - Refit the optimized model
 - Evaluate
 - Run predictions



















